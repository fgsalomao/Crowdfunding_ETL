# Crowdfunding ETL
ETL pipeline (Python, Pandas, RegEx, ERD, table schema Postgres SQL)

![ETL Image](https://github.com/fgsalomao/Crowdfunding_ETL/blob/main/ETL.jpg)

# Project Scope

### Python and Pandas üêçüêº

- Extract data using Python and Pandas.
- Transform and clean data using Python and Pandas.
- Parse string data into a Python dictionary.
- Utilize list comprehension to enhance code readability.
- Apply regular expressions to manipulate string data.

### Data Wrangling using RegEx üßπüß©

- Use wildcards, sets, and escape characters in regular expressions to extract information.
- Utilize special characters in regular expressions to extract information.
- Create and use capture groups in regular expressions to extract information.

### Creating a database and Loading finish data üõ†Ô∏èüìä

- Create an entity relationship diagram from CSV files.
- Design a table schema.
- Import CSV files into a PostgreSQL database.
- Discuss the benefits and challenges of the ETL process.

## Benefits :white_check_mark:

### 1. Data Integration :chart_with_upwards_trend:
- Facilitates the integration of data from various sources into a unified format, ensuring consistency and coherence.

### 2. Improved Data Quality :bar_chart:
- Often includes data cleaning and transformation steps, leading to enhanced data quality.
- Identifying and handling errors during the transformation phase makes the data more reliable.

### 3. Business Intelligence and Reporting :chart_with_downwards_trend:
- Plays a crucial role in preparing data for business intelligence and reporting applications.
- Transformed and structured data is easier to analyze, providing meaningful insights for decision-making.

### 4. Enhanced Performance :rocket:
- Pre-processing and optimizing data before loading it into a data warehouse or analytics platform contribute to improved query performance and faster data retrieval.

### 5. Automation and Efficiency :robot:
- Workflows can be automated, reducing manual effort and ensuring that data is updated regularly.
- This automation enhances efficiency, allowing organizations to focus on analysis rather than data wrangling.

## Challenges :warning:

### 1. Complexity :twisted_rightwards_arrows:
- Can become intricate, especially in large organizations with diverse data sources.
- Managing transformations and ensuring data consistency across systems can be challenging.

### 2. Data Latency :hourglass_flowing_sand:
- Depending on the frequency of jobs, there may be latency between data extraction and its availability for analysis.
- Real-time data processing requirements might not be fully met by traditional methods.

### 3. Data Security :lock:
- Involves moving and transforming data, raising concerns about security.
- Ensuring that sensitive information is handled appropriately throughout the workflow is crucial to prevent breaches.

### 4. Scalability :chart:
- As data volumes grow, scalability becomes a concern.
- Designing processes that can handle increasing data loads while maintaining performance requires careful planning and architecture.

### 5. Maintenance :wrench:
- Needs regular maintenance to accommodate changes in data sources, business requirements, or technology upgrades.
- Keeping workflows up-to-date and aligned with evolving business needs can be resource-intensive.

## Conclusion :bulb:

In conclusion, while data integration and transformation processes offer significant benefits in terms of data quality, analytics preparation, and efficiency, addressing challenges related to complexity, latency, security, scalability, and maintenance is essential for successful implementation in data-driven environments.
